{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475bfd19-fae6-4191-99e3-14722206dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f68b9d-1b66-4b75-b438-8b62831ea2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv('C:/Users/dell/Documents/Guvi Lectures/Swiggy model/swiggy_cleaned_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdae23fe-2602-4323-8108-0e635abd3a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>rating</th>\n",
       "      <th>cost</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB FOODS POINT</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Beverages,Pizzas</td>\n",
       "      <td>AB FOODS POINT, NEAR RISHI NARANG DENTAL CLINI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Janta Sweet House</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>4.4</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sweets,Bakery</td>\n",
       "      <td>Janta Sweet House, Bazar No.9, Circullar Road,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theka coffee desi</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>3.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>theka coffee desi, sahtiya sadan road city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singh Hut</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>3.7</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Fast Food,Indian</td>\n",
       "      <td>Singh Hut, CIRCULAR ROAD NEAR NEHRU PARK ABOHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRILL MASTERS</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Italian-American,Fast Food</td>\n",
       "      <td>GRILL MASTERS, ADA Heights, Abohar - Hanumanga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148393</th>\n",
       "      <td>The Food Delight</td>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Fast Food,Snacks</td>\n",
       "      <td>The Food Delight, 94MC+X35, New Singhania Naga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148394</th>\n",
       "      <td>MAITRI FOODS &amp; BEVERAGES</td>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Pizzas</td>\n",
       "      <td>MAITRI FOODS &amp; BEVERAGES, POLIC MITRYA SOCIETY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148395</th>\n",
       "      <td>Cafe Bella Ciao</td>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Fast Food,Snacks</td>\n",
       "      <td>Cafe Bella Ciao, SHOP NO 2 NEMANI MARKET SBI S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148396</th>\n",
       "      <td>GRILL ZILLA</td>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Continental</td>\n",
       "      <td>GRILL ZILLA, SHO NO 2/6, POSTEL GROUND CHOWPAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148397</th>\n",
       "      <td>Lazeez kitchen</td>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Pizzas</td>\n",
       "      <td>Lazeez kitchen, 94G3+2RR, Wadgaon, Yavatmal, M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148398 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name      city  rating   cost  \\\n",
       "0                 AB FOODS POINT    Abohar     4.0  200.0   \n",
       "1              Janta Sweet House    Abohar     4.4  200.0   \n",
       "2              theka coffee desi    Abohar     3.8  100.0   \n",
       "3                      Singh Hut    Abohar     3.7  250.0   \n",
       "4                  GRILL MASTERS    Abohar     4.0  250.0   \n",
       "...                          ...       ...     ...    ...   \n",
       "148393          The Food Delight  Yavatmal     4.0  200.0   \n",
       "148394  MAITRI FOODS & BEVERAGES  Yavatmal     4.0  300.0   \n",
       "148395           Cafe Bella Ciao  Yavatmal     4.0  300.0   \n",
       "148396               GRILL ZILLA  Yavatmal     4.0  250.0   \n",
       "148397            Lazeez kitchen  Yavatmal     4.0  200.0   \n",
       "\n",
       "                           cuisine  \\\n",
       "0                 Beverages,Pizzas   \n",
       "1                    Sweets,Bakery   \n",
       "2                        Beverages   \n",
       "3                 Fast Food,Indian   \n",
       "4       Italian-American,Fast Food   \n",
       "...                            ...   \n",
       "148393            Fast Food,Snacks   \n",
       "148394                      Pizzas   \n",
       "148395            Fast Food,Snacks   \n",
       "148396                 Continental   \n",
       "148397                      Pizzas   \n",
       "\n",
       "                                                  address  \n",
       "0       AB FOODS POINT, NEAR RISHI NARANG DENTAL CLINI...  \n",
       "1       Janta Sweet House, Bazar No.9, Circullar Road,...  \n",
       "2              theka coffee desi, sahtiya sadan road city  \n",
       "3         Singh Hut, CIRCULAR ROAD NEAR NEHRU PARK ABOHAR  \n",
       "4       GRILL MASTERS, ADA Heights, Abohar - Hanumanga...  \n",
       "...                                                   ...  \n",
       "148393  The Food Delight, 94MC+X35, New Singhania Naga...  \n",
       "148394  MAITRI FOODS & BEVERAGES, POLIC MITRYA SOCIETY...  \n",
       "148395  Cafe Bella Ciao, SHOP NO 2 NEMANI MARKET SBI S...  \n",
       "148396  GRILL ZILLA, SHO NO 2/6, POSTEL GROUND CHOWPAT...  \n",
       "148397  Lazeez kitchen, 94G3+2RR, Wadgaon, Yavatmal, M...  \n",
       "\n",
       "[148398 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17437da3-c209-4d0d-9b88-daeb32e8c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = cleaned_data.drop(columns=[\"name\",\"address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f45ea6d-fe37-45f0-af96-82f5a57784ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>rating</th>\n",
       "      <th>cost</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Beverages,Pizzas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>4.4</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sweets,Bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>3.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>3.7</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Fast Food,Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Italian-American,Fast Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148393</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Fast Food,Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148394</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Pizzas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148395</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Fast Food,Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148396</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Continental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148397</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Pizzas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148398 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  rating   cost                     cuisine\n",
       "0         Abohar     4.0  200.0            Beverages,Pizzas\n",
       "1         Abohar     4.4  200.0               Sweets,Bakery\n",
       "2         Abohar     3.8  100.0                   Beverages\n",
       "3         Abohar     3.7  250.0            Fast Food,Indian\n",
       "4         Abohar     4.0  250.0  Italian-American,Fast Food\n",
       "...          ...     ...    ...                         ...\n",
       "148393  Yavatmal     4.0  200.0            Fast Food,Snacks\n",
       "148394  Yavatmal     4.0  300.0                      Pizzas\n",
       "148395  Yavatmal     4.0  300.0            Fast Food,Snacks\n",
       "148396  Yavatmal     4.0  250.0                 Continental\n",
       "148397  Yavatmal     4.0  200.0                      Pizzas\n",
       "\n",
       "[148398 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c742bc-05f8-4140-b7fb-eb9748a799ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city       0\n",
       "rating     0\n",
       "cost       0\n",
       "cuisine    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c95c5f-7b47-485a-aa41-4b74d5d44098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done File Saved!\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.to_csv(\"swiggy_cleaned_revised.csv\",index=False)\n",
    "print(\"Done File Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "659cf73c-a246-48c7-b213-74f861e2ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ac5cb7-41a2-47a4-8e93-b25d53e38003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "     city  rating   cost                     cuisine\n",
      "0  Abohar     4.0  200.0            Beverages,Pizzas\n",
      "1  Abohar     4.4  200.0               Sweets,Bakery\n",
      "2  Abohar     3.8  100.0                   Beverages\n",
      "3  Abohar     3.7  250.0            Fast Food,Indian\n",
      "4  Abohar     4.0  250.0  Italian-American,Fast Food\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.36 GiB for an array with shape (2132, 148398) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m encoded_cuisines_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(encoded_cuisines, columns\u001b[38;5;241m=\u001b[39mencoder\u001b[38;5;241m.\u001b[39mget_feature_names_out([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisine\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Drop original 'cuisine' column and concatenate the encoded DataFrame\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuisine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_cuisines_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Save the processed DataFrame as encoded_data.csv\u001b[39;00m\n\u001b[0;32m     31\u001b[0m processed_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_data_updated.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     mgrs \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_reindex_columns_na_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnblocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[0;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    221\u001b[0m             axes[i],\n\u001b[0;32m    222\u001b[0m             indexers[i],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[1;32m--> 230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     new_mgrs\u001b[38;5;241m.\u001b[39mappend(mgr)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.36 GiB for an array with shape (2132, 148398) and data type float64"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = 'C:/Users/dell/Documents/Guvi Lectures/Swiggy model/swiggy_cleaned_revised.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print('Initial DataFrame:')\n",
    "print(df.head())\n",
    "\n",
    "# Handling missing values\n",
    "# Replace '--' with NaN and fill with the median for numerical columns\n",
    "numerical_columns = ['rating', 'cost']\n",
    "df.replace('--', np.nan, inplace=True)\n",
    "df[numerical_columns] = df[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Apply One-Hot Encoding to categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cuisines = encoder.fit_transform(df[['cuisine']])\n",
    "\n",
    "# Save the encoder as a pickle file\n",
    "with open('encoder_updated.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "# Convert the encoded data to a DataFrame\n",
    "encoded_cuisines_df = pd.DataFrame(encoded_cuisines, columns=encoder.get_feature_names_out(['cuisine']))\n",
    "\n",
    "# Drop original 'cuisine' column and concatenate the encoded DataFrame\n",
    "processed_df = pd.concat([df.drop('cuisine', axis=1), encoded_cuisines_df], axis=1)\n",
    "\n",
    "# Save the processed DataFrame as encoded_data.csv\n",
    "processed_df.to_csv('encoded_data_updated.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the processed DataFrame\n",
    "print('Processed DataFrame:')\n",
    "print(processed_df.head())\n",
    "\n",
    "print('✅ Data preprocessing completed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7ad7c2-5041-4c58-bb24-014c2fd6d451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_19276\\3521837366.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_19276\\3521837366.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_19276\\3521837366.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_19276\\3521837366.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.26 GiB for an array with shape (148398, 2953) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Combine encoded categorical features with numerical features\u001b[39;00m\n\u001b[0;32m     32\u001b[0m numerical_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisine\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m csr_matrix(np\u001b[38;5;241m.\u001b[39mhstack((numerical_features\u001b[38;5;241m.\u001b[39mvalues, \u001b[43mencoded_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Save the sparse matrix\u001b[39;00m\n\u001b[0;32m     36\u001b[0m save_npz(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_data_sparse.npz\u001b[39m\u001b[38;5;124m'\u001b[39m, encoded_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1170\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1170\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_base.py:1366\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.26 GiB for an array with shape (148398, 2953) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import save_npz, csr_matrix\n",
    "\n",
    "# Load the cleaned data\n",
    "file_path = 'C:/Users/dell/Documents/Guvi Lectures/Swiggy model//swiggy_cleaned_revised.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop 'address' column as it's not useful for recommendation\n",
    "if 'address' in df.columns:\n",
    "    df = df.drop(columns=['address'])\n",
    "\n",
    "# Handle missing values by filling with mode for categorical and median for numerical\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Apply One-Hot Encoding to categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "categorical_features = df[['city', 'cuisine']]\n",
    "encoded_features = encoder.fit_transform(categorical_features)\n",
    "\n",
    "# Save the encoder as a pickle file\n",
    "with open('encoder_true_copy.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "# Combine encoded categorical features with numerical features\n",
    "numerical_features = df.drop(columns=['city', 'cuisine']).astype('float32')\n",
    "encoded_data = csr_matrix(np.hstack((numerical_features.values, encoded_features.toarray())))\n",
    "\n",
    "# Save the sparse matrix\n",
    "save_npz('encoded_data_sparse.npz', encoded_data)\n",
    "\n",
    "print('✅ Sparse data generated and saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a4b7fea-67be-4f56-90f2-541baf85b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sparse matrix created and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import save_npz, csr_matrix\n",
    "\n",
    "\n",
    "# Load cleaned data\n",
    "file_path = 'C:/Users/dell/Documents/Guvi Lectures/Swiggy model/swiggy_cleaned_revised.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# # Drop irrelevant columns\n",
    "# if 'address' in df.columns:\n",
    "#     df = df.drop(columns=['address'])\n",
    "\n",
    "# # Convert 'cost' to numeric after cleaning currency symbols and commas\n",
    "# if df['cost'].dtype == 'object':\n",
    "#     df['cost'] = pd.to_numeric(df['cost'].replace('[₹,]', '', regex=True), errors='coerce')\n",
    "\n",
    "# # Fill missing numeric values with the median\n",
    "# if df['rating'].isnull().any():\n",
    "#     df['rating'].fillna(df['rating'].median(), inplace=True)\n",
    "\n",
    "# df.fillna(0, inplace=True)  # Fill any remaining NaN values with 0\n",
    "\n",
    "\n",
    "# Initialize One-Hot Encoder\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "\n",
    "\n",
    "# Fit encoder on 'city' and 'cuisine'\n",
    "categorical_features = df[['city', 'cuisine']]\n",
    "encoded_features = encoder.fit_transform(categorical_features)\n",
    "\n",
    "\n",
    "# Save the encoder as a pickle file\n",
    "with open('encoder_today.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "\n",
    "# Save the sparse matrix\n",
    "save_npz('encoded_data_sparse.npz', encoded_features)\n",
    "\n",
    "\n",
    "print('✅ Sparse matrix created and saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b97c1-114e-4255-a36b-e3bb9d6ccdce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
